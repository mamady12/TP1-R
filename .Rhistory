# ----- Chargement des fonctions utiles
source("./fonctions_tp_RegLog.R")
setwd("C:/Users/wizzk/Desktop/M2/S1/FST/TP1")
# ----- Chargement des fonctions utiles
source("./fonctions_tp_RegLog.R")
source("./nnets.R")
library(e1071)
# ----- Chargement des donnÃ©es (prenez le fichier qui vous est associÃ©)
ex1 = read.table("./donnees_exo1.txt", header = T)
# Affichage du dÃ©but des donnÃ©es
head(ex1) # Cette commande affiche les 6 premiÃ¨res lignes du tableau ex1
# Question
# Combien de variables dÃ©crivent les individus de ce jeu de donnÃ©es ? Comment s'appellent t'elles?
dim(ex1)
# ----- Chargement des fonctions utiles
source("./fonctions_tp_RegLog.R")
source("./nnets.R")
library(e1071)
# ----- Chargement des donnÃ©es (prenez le fichier qui vous est associÃ©)
ex1 = read.table("./donnees_exo1.txt", header = T)
# Affichage du dÃ©but des donnÃ©es
head(ex1) # Cette commande affiche les 6 premiÃ¨res lignes du tableau ex1
# Question
# Combien de variables dÃ©crivent les individus de ce jeu de donnÃ©es ? Comment s'appellent t'elles?
dim(ex1)
# Combien y a t'il d'individus dans ce jeu de donnÃ©es ?
dim(ex1)
#118 lignes et 3 colonnes
# Quelles sont les valeurs des variables descriptives de l'individu numÃ©ro 12 ?
ex1[12,]
ex1$Classe
class(ex1$Classe)
#58
length(which(ex1$Classe==0))
#60
# Que vaut la moyenne de la variable X?
summary(ex1$X)
mean(ex1$X)
#Mean=0.05779
# Que vaut la moyenne de la variable Y?
mean(ex1$Y)
#Mean=0.1831016
# Que vaut la moyenne de la variable X pour les individus de la classe 0 ?
mean(ex1[which(ex1$Classe==0),1])
# ----- Affichage du jeu de donnÃ©es
plot(ex1[which(ex1$Classe==0), 1:2], col = "blue")
points(ex1[which(ex1$Classe==1), 1:2], col = "red")
# ----- Separation Apprentissage/Validation/Test
# On va mettre 70% des individus dans un ensemble d'apprentissage, 15% dans un ensemble de validation et 15% dans un ensemble de test
# Le mieux est de le faire de faÃ§on alÃ©atoire (et non pas garder l'ordre du jeu de donnÃ©es initial)
# Pour cela, vous pouvez utiliser la commande sample(118) qui gÃ©nÃ¨re une permutation alÃ©atoire
# de l'ensemble [1, ..., 118] (118 ici car on a 118 individus)
idx_random = sample(118)
idx_random
# Puis, on va permuter les lignes de ex1 grÃ¢ce Ã  cette permutation alÃ©atoire :
ex1 = ex1[idx_random,]
ex1
# Puis, on va permuter les lignes de ex1 grÃ¢ce Ã  cette permutation alÃ©atoire :
ex1 = ex1[idx_random,]
# Question :
# CrÃ©er un tableau ex1_app (ensemble d'apprentissage) qui contient 70 % des individus de ex1 (ensemble d'apprentissage)
# Aide : 70% de 118, fait environ 82. Donc vous devez prendre les 82 premiÃ¨res lignes de ex1 (qui a Ã©tÃ©
# permutÃ© alÃ©atoirement)
ex1_app=(ex1[1:82,])
ex1_app
# Puis crÃ©er ex1_val (ensemble de validation) en mettant les 18 individus (15%) suivants de ex1
ex1_val=ex1[83:100,]
ex1_val
dim(ex1_val)
# Et enfin, ex1_test (ensemble de test) en mettant les 18 derniers individus (15%) de ex1
ex1_test=ex1[101:118,]
ex1_test
dim(ex1_test)
#Affichage des donnÃ©es d apprentissage
# D'abord ceux qui ont Ã©chouÃ©s (pour lesquels ex1$Reussite = 0) en rouge
plot(ex1_app[which(ex1_app$Classe==0),1:2], col = "red", xlim = c(-1,1.2), ylim = c(-0.85,1.2))
# puis ceux qui ont rÃ©ussis, en bleu
points(ex1_app[which(ex1_app$Classe==1),1:2], col = "blue")
# Affichage des donnÃ©es de validation (on les affiche avec un triangle , pch = 2)
points(ex1_val[which(ex1_val$Classe==1),1:2], col = "blue", pch = 2)
points(ex1_val[which(ex1_val$Classe==0),1:2], col = "red", pch = 2)
# ----- Estimation du modele de regression logistique sur les donnÃ©es d apprentissage
# On utilise la fonction glm. On doit lui indiquer le nom de la colonne dans laquelle est stockÃ©e la variable
# cible, ici Classe. On utilise le . pour dire qu'on prends toutes les autres colonnes comme descripteurs des individus pour construire le classifieur.
# Le terme "family = binomial(link = 'logit')" sert Ã  prÃ©ciser que l'on fait de la rÃ©gression logistique
reg_ex1 = glm(Classe~., data = ex1_app, family = binomial(link = 'logit'))
# Question :
# Sans regarder le modÃ¨le (pour l'instant), combien de paramÃ¨tres ont Ã©tÃ© estimÃ©s dans ce modÃ¨le ?
# 3 parametre: une constante + les 2 variable explicative X et Y
# Affichage du modÃ¨le
reg_ex1
# Calculez Ã  la main (enfin en utilisant la console R quand mÃªme) la sortie du modÃ¨le associÃ©e au premier
# individu de votre ensemble d'apprentissage. Aide : il suffit d'appliquer l'Ã©quation du modÃ¨le avec les donnÃ©es de cet individu.
var=(1/(1+exp(-(-0.1561-0.5429*(-0.0466590)+0.2786*(-0.579680)))))
var
# Vous pouvez calculer directement la sortie du modÃ¨le avec la commande predict:
idx = 1 # pour dire qu'on regarde le 1er individu pour l'instant
p = predict(reg_ex1, ex1_app[idx,], type = 'response')
p
# VÃ©rifier que le rÃ©sultat est bien le mÃªme que celui que vous avez obtenu juste avant.
# verification OK
# Ecrivez une commande qui permet de dÃ©terminer Ã  partir de la probabilitÃ© obtenue ci-dessus, la classe (prÃ©dite par la modÃ¨le) de l'individu
# Aide : commande ifelse(condition, reponse si oui, reponse si non)
# A REMPLIR
ifelse(var>=0.5,1,0)
# Estimez la classe de chacun des individus du jeu d'apprentissage.
# Aide : appliquer la commande predict Ã  tout le jeu d'apprentissage, puis ifelse de la mÃªme faÃ§on
# A REMPLIR
predict_app=predict(reg_ex1, ex1_app, type = 'response')
predict_app
p_app=ifelse(predict_app>=0.5,1,0)
p_app
# A REMPLIR
p_app!=ex1_app$Classe
Nbre_err=sum((p_app!=ex1_app$Classe))
Nbre_err
# A REMPLIR
ex1_app$Classe
p_app
Mat=table(p_app,ex1_app$Classe)
Mat
# A REMPLIR
ex1_val
predict_valid=predict(reg_ex1, ex1_val, type = 'response')
predict_valid
p_valid=ifelse(predict_valid>=0.5,1,0)
p_valid
#la prediction
p_valid
#la classe validation
ex1_val$Classe
#diff en la prediction et la classe de validation
p_valid!=ex1_val$Classe
#comptage du nombre d'erreur
Nbre_err_val=sum((p_valid!=ex1_val$Classe))
Nbre_err_val
#Matrice de confusion
Mat_val=table(p_valid,ex1_val$Classe)
Mat_val
# Idem pour l'ensemble de test
ex1_test
predict_test=predict(reg_ex1, ex1_test, type = 'response')
predict_test
p_test=ifelse(predict_test>=0.5,1,0)
p_test
#la prediction
p_test
#la classe validation
ex1_test$Classe
#diff en la prediction et la classe de validation
p_test!=ex1_test$Classe
#comptage du nombre d'erreur
Nbre_err_tes=sum((p_test!=ex1_test$Classe))
Nbre_err_tes
#Matrice de confusion
Mat_val=table(p_test,ex1_test$Classe)
#tous les individus de la classe ont été predit a 0
#la matrice de confusion indique que 7 indivus ont été predit classe0 alors qu'il etait de la clase 1
Mat_val
# TracÃ© de la frontiÃ¨re de dÃ©cision
# La fonction remplissage (donnÃ©e dans le fichier fonctions_tp_RegLog, allez voir les explications) vous permet de visualiser la frontiÃ¨re de dÃ©cision
# Le principe : prÃ©dire tous les points du plan et les afficher avec la couleur associÃ©e Ã  la prÃ©diction.
# Vous remarquerez que les donnÃ©es d'apprentissage et de validation sont Ã©galement affichÃ©es
# Ici le paramÃ¨tre puissance est mis Ã  1, les couleurs sont rouge et bleus (vous pouvez changer)
remplissage(ex1_app, ex1_val, reg_ex1,1,"red","blue",-1,1.2,-0.85,1.2)
# Remplir la fonction calcul_erreur du fichier fonctions_tp_RegLog (allez voir sa description) et vÃ©rifier que les rÃ©sultats sont corrects (identiques Ã  ceux obtenus avant)
source("./fonctions_tp_RegLog.R")
calcul_erreur(ex1_app, ex1_val, ex1_test, reg_ex1, 3)
#CrÃ©ation des nouveaux jeux de donnÃ©es (apprentissage, validation et test)
head(ex1_app)
pow = c(2:30)
ex1_d2_app = puissance(ex1_app,pow)
ex1_d2_val = puissance(ex1_val,pow)
ex1_d2_test = puissance(ex1_test,pow)
# Affichage du dÃ©but de ex1_d2_app
head(ex1_d2_app)
dim(ex1_d2_app)
#Question :
# Comparer (manuellement) la premiÃ¨re ligne de ex1_app (individu numÃ©ro 1 du jeu de donnÃ©es initial) et la premiÃ¨re ligne de ex1_d2_app (individu numÃ©ro 1 avec les nouvelles variables). Dans quelles colonnes sont mises les nouvelles variables ? Vous remarquerez que la variable cible (Classe) est toujours en derniÃ¨re colonne. RepÃ©rez l'indice de cette derniÃ¨re colonne
# X3 et X4
# Indice col classe = 5
ncol(ex1_d2_app)
# Calcul du modÃ¨le de regression logistique associÃ© aux donnÃ©es d apprentissage
reg_ex1_d2 = glm(Classe~., data = ex1_d2_app, family = binomial(link = 'logit'))
# TracÃ© de la frontiÃ¨re de dÃ©cision (on indique  le nouveau nom du modÃ¨le et que les donnÃ©es sont Ã  la puissance 2)
remplissage(ex1_app, ex1_val, reg_ex1_d2,2,"red","blue",-1,1.2,-0.85,1.2)
# A FAIRE
source("./fonctions_tp_RegLog.R")
calcul_erreur(ex1_d2_app, ex1_d2_val, ex1_d2_test, reg_ex1_d2, ncol(ex1_d2_app))
ex1_d2_app = puissance(ex1_app,pow)
ex1_d2_val = puissance(ex1_val,pow)
ex1_d2_test = puissance(ex1_test,pow)
#Question :
# Comparer (manuellement) la premiÃ¨re ligne de ex1_app (individu numÃ©ro 1 du jeu de donnÃ©es initial) et la premiÃ¨re ligne de ex1_d2_app (individu numÃ©ro 1 avec les nouvelles variables). Dans quelles colonnes sont mises les nouvelles variables ? Vous remarquerez que la variable cible (Classe) est toujours en derniÃ¨re colonne. RepÃ©rez l'indice de cette derniÃ¨re colonne
# X3 et X4
# Indice col classe = 5
ncol(ex1_d2_app)
# Calcul du modÃ¨le de regression logistique associÃ© aux donnÃ©es d apprentissage
reg_ex1_d2 = glm(Classe~., data = ex1_d2_app, family = binomial(link = 'logit'))
# TracÃ© de la frontiÃ¨re de dÃ©cision (on indique  le nouveau nom du modÃ¨le et que les donnÃ©es sont Ã  la puissance 2)
remplissage(ex1_app, ex1_val, reg_ex1_d2,2,"red","blue",-1,1.2,-0.85,1.2)
# TracÃ© de la frontiÃ¨re de dÃ©cision (on indique  le nouveau nom du modÃ¨le et que les donnÃ©es sont Ã  la puissance 2)
remplissage(ex1_app, ex1_val, reg_ex1_d2,2,"red","blue",-1,1.2,-0.85,1.2)
head(ex1_app)
pow = c(2:30)
ex1_d2_app = puissance(ex1_app,pow)
ex1_d2_val = puissance(ex1_val,pow)
ex1_d2_test = puissance(ex1_test,pow)
# Affichage du dÃ©but de ex1_d2_app
head(ex1_d2_app)
dim(ex1_d2_app)
#Question :
# Comparer (manuellement) la premiÃ¨re ligne de ex1_app (individu numÃ©ro 1 du jeu de donnÃ©es initial) et la premiÃ¨re ligne de ex1_d2_app (individu numÃ©ro 1 avec les nouvelles variables). Dans quelles colonnes sont mises les nouvelles variables ? Vous remarquerez que la variable cible (Classe) est toujours en derniÃ¨re colonne. RepÃ©rez l'indice de cette derniÃ¨re colonne
# X3 et X4
# Indice col classe = 5
ncol(ex1_d2_app)
# Calcul du modÃ¨le de regression logistique associÃ© aux donnÃ©es d apprentissage
reg_ex1_d2 = glm(Classe~., data = ex1_d2_app, family = binomial(link = 'logit'))
# TracÃ© de la frontiÃ¨re de dÃ©cision (on indique  le nouveau nom du modÃ¨le et que les donnÃ©es sont Ã  la puissance 2)
remplissage(ex1_app, ex1_val, reg_ex1_d2,2,"red","blue",-1,1.2,-0.85,1.2)
# Remplir la fonction calcul_erreur du fichier fonctions_tp_RegLog (allez voir sa description) et vÃ©rifier que les rÃ©sultats sont corrects (identiques Ã  ceux obtenus avant)
source("./fonctions_tp_RegLog.R")
calcul_erreur(ex1_app, ex1_val, ex1_test, reg_ex1, 3)
#CrÃ©ation des nouveaux jeux de donnÃ©es (apprentissage, validation et test)
head(ex1_app)
pow = c(2:30)
ex1_d2_app = puissance(ex1_app,pow)
ex1_d2_val = puissance(ex1_val,pow)
ex1_d2_test = puissance(ex1_test,pow)
# Affichage du dÃ©but de ex1_d2_app
head(ex1_d2_app)
dim(ex1_d2_app)
#Question :
# Comparer (manuellement) la premiÃ¨re ligne de ex1_app (individu numÃ©ro 1 du jeu de donnÃ©es initial) et la premiÃ¨re ligne de ex1_d2_app (individu numÃ©ro 1 avec les nouvelles variables). Dans quelles colonnes sont mises les nouvelles variables ? Vous remarquerez que la variable cible (Classe) est toujours en derniÃ¨re colonne. RepÃ©rez l'indice de cette derniÃ¨re colonne
# X3 et X4
# Indice col classe = 5
ncol(ex1_d2_app)
# Calcul du modÃ¨le de regression logistique associÃ© aux donnÃ©es d apprentissage
reg_ex1_d2 = glm(Classe~., data = ex1_d2_app, family = binomial(link = 'logit'))
# TracÃ© de la frontiÃ¨re de dÃ©cision (on indique  le nouveau nom du modÃ¨le et que les donnÃ©es sont Ã  la puissance 2)
remplissage(ex1_app, ex1_val, reg_ex1_d2,2,"red","blue",-1,1.2,-0.85,1.2)
# A FAIRE
source("./fonctions_tp_RegLog.R")
calcul_erreur(ex1_d2_app, ex1_d2_val, ex1_d2_test, reg_ex1_d2, ncol(ex1_d2_app))
ex1_d2_app_X = puissance(ex1_app,c(2:3))
ex1_d2_val_X = puissance(ex1_val,c(2:3))
ex1_d2_test_X = puissance(ex1_test,c(2:3))
# Indice col classe =7
ncol(ex1_d2_app_X)
reg_ex1_d2_X = glm(Classe~., data = ex1_d2_app_X, family = binomial(link = 'logit'))
calcul_erreur(ex1_d2_app_X, ex1_d2_val_X, ex1_d2_test_X,reg_ex1_d2_X, 7)
remplissage(ex1_app, ex1_val, reg_ex1_d2_X,c(2:3),"red","blue",-1,1.2,-0.85,1.2)
ex1_d2_app_10 = puissance(ex1_app,c(2:12))
ex1_d2_app_10 = puissance(ex1_app,c(2:12))
ex1_d2_val_10 = puissance(ex1_val,c(2:12))
ex1_d2_test_10 = puissance(ex1_test,c(2:12))
ex1_d2_app_10
reg_ex1_d2_10 = glm(Classe~., data = ex1_d2_app_10, family = binomial(link = 'logit'))
reg_ex1_d2_10 = glm(Classe~., data = ex1_d2_app_10, family = binomial(link = 'logit'))
dim(ex1_d2_app_10)
calcul_erreur(ex1_d2_app_10, ex1_d2_val_10, ex1_d2_test_10,reg_ex1_d2_10,25 )
remplissage(ex1_app, ex1_val, reg_ex1_d2_10,c(2:12),"red","blue",-1,1.2,-0.85,1.2)
# 2:100
ex1_d2_app_100 = puissance(ex1_app,c(2:100))
ex1_d2_val_100 = puissance(ex1_val,c(2:100))
ex1_d2_test_100 = puissance(ex1_test,c(2:100))
reg_ex1_d2_100 = glm(Classe~., data = ex1_d2_app_100, family = binomial(link = 'logit'))
dim(ex1_d2_app_100)
calcul_erreur(ex1_d2_app_100, ex1_d2_val_100, ex1_d2_test_100,reg_ex1_d2_100,201 )
remplissage(ex1_app, ex1_val, reg_ex1_d2_100,c(2:12),"red","blue",-1,1.2,-0.85,1.2)
#tous les erreurs
calcul_erreur(ex1_app, ex1_val, ex1_test, reg_ex1, 3)
calcul_erreur(ex1_d2_app_X, ex1_d2_val_X, ex1_d2_test_X,reg_ex1_d2_X, 7)
calcul_erreur(ex1_d2_app_10, ex1_d2_val_10, ex1_d2_test_10,reg_ex1_d2_10,25 )
# Chargement des donnÃ©es (on a dÃ©jÃ  fait pour vous 3 ensembles A/V/T)
cp_app= read.table("./chiffres_app.txt", header=T)
cp_val= read.table("./chiffres_val.txt", header=T)
cp_test= read.table("./chiffres_test.txt", header=T)
# Regardez la dimension de l'ensemble d'apprentissage
dim(cp_app)
# Il comporte 150 lignes (qui correspondent Ã  150 images de chiffres). Ces chiffres sont reprÃ©sentÃ©s par
# 784 pixels (image de taille 28*28). Les colonnes pixel0, pixel1, etc... reprÃ©sentent les valeurs de pixels pour chaque image (0 ou 1, noir ou blanc). La colonne label reprÃ©sente le chiffre qui est inscrit sur l'image (de 1 Ã  10, sachant que la classe 10 reprÃ©sente les zÃ©ros).
head(cp_app)
# Question : Quelle est la valeur du 7Ã¨me pixel de l'image 4 de l'ensemble d'apprentissage ? Aide : il faut aller chercher l'Ã©lÃ©ment Ã  la ligne 4 et colonne 8 (car la premiere colonne est le label) de cp_app
cp_app[4,8]
# Quel est le chiffre reprÃ©sentÃ© sur l'image 4 de l'ensemble d'apprentissage ? Ligne 4 colonne 1 ...
cp_app[4,1]
reg_ex1_d2_100
# Chargement des donnÃ©es (on a dÃ©jÃ  fait pour vous 3 ensembles A/V/T)
cp_app= read.table("./chiffres_app.txt", header=T)
cp_val= read.table("./chiffres_val.txt", header=T)
cp_test= read.table("./chiffres_test.txt", header=T)
# Regardez la dimension de l'ensemble d'apprentissage
dim(cp_app)
# Il comporte 150 lignes (qui correspondent Ã  150 images de chiffres). Ces chiffres sont reprÃ©sentÃ©s par
# 784 pixels (image de taille 28*28). Les colonnes pixel0, pixel1, etc... reprÃ©sentent les valeurs de pixels pour chaque image (0 ou 1, noir ou blanc). La colonne label reprÃ©sente le chiffre qui est inscrit sur l'image (de 1 Ã  10, sachant que la classe 10 reprÃ©sente les zÃ©ros).
head(cp_app)
# Question : Quelle est la valeur du 7Ã¨me pixel de l'image 4 de l'ensemble d'apprentissage ? Aide : il faut aller chercher l'Ã©lÃ©ment Ã  la ligne 4 et colonne 8 (car la premiere colonne est le label) de cp_app
cp_app[4,8]
# Quel est le chiffre reprÃ©sentÃ© sur l'image 4 de l'ensemble d'apprentissage ? Ligne 4 colonne 1 ...
cp_app[4,1]
# Quelles sont les dimensions des ensembles de validation et de test ?
dim(cp_test)
dim(cp_val)
# La fonction display du fichier tp1_RegLog.R permet de visualiser les images que l'on a Ã  notre disposition
idx = 8# pour afficher la 4Ã¨me image (vous pourrez changer)
display(matrix(as.numeric(cp_app[idx,2:785]), byrow = T,ncol = 28))
# On utilise maintenant la fonction learn_nn (de nnets.R) car glm ne fonctionne que pour de la classification binaire (deux classes)
# Cette fonction apprend un modÃ¨le de rÃ©gression logistique multi-classes (donc plusieurs modÃ¨les de rÃ©gression logistique) Ã  partir d'un ensemble d'apprentissage
# Les paramÃ¨tres de cette fonction sont:
# 1) une matrice contenant les donnÃ©es d'apprentissage (sans les classes). Individus en lignes
# 2) un vecteur contenant les classes des individus de l'ensemble d'apprentissage (dans l'ordre de la matrice du premier paramÃ¨tre)
# 3) lambda, pour l'instant ce sera toujours 0 ( on verra si on a le temps d'en parler)
# 4) nombre d'itÃ©rations pour trouver le meilleur modÃ¨le. Ici j'ai mis 100 car les donnÃ©es sont volumineuses donc c'est long. On pourra mettre une valeur plus grande dans d'autres circonstances.
# 5) un vecteur avec 2 valeurs : nombre de variables d'entrÃ©e (ici 784 pixels) et nombre de classes distinctes (ici 10 car dix chiffres)
# Lancez cette commande et soyez un peu patients (cela prend 1 minute environ). C'est moi qui l'ai implementÃ©e et je n'ai pas du tout fait au plus efficace!
RL_chiffres = learn_nn(cp_app[,2:785], cp_app$label, 0,100, c(784, 10))
# Question : Combien de coefficients comportent ce modÃ¨le ? Sans regarder RL_chiffres[[1]] ...
#785
# VÃ©rifiez en affichant la dimension de cette matrice de coefficient :
dim(RL_chiffres[[1]])
RL_chiffres
# Question : Calculer les sorties du modÃ¨le lorsque l'on tente de prÃ©dire la classe de l'image numÃ©ro 2 du jeu d'apprentissage
# Quel chiffre allez-vous prÃ©dire pour cette image ?
calcul_sorties(RL_chiffres,cp_app[2,2:785])
#Dans la prediction 10=0
# 0 car il a le score le plus élévé
display(matrix(as.numeric(cp_app[2,2:785]), byrow = T,ncol = 28))
which.max(calcul_sorties(RL_chiffres,cp_app[2,2:785]))
calcul_sorties(RL_chiffres,cp_app[,2:785])
# Question :
# Quelle est la vraie classe de la 3 Ã¨me image ? (utilisez display ou bien regarder le label de la 3 Ã¨me ligne de cp_app)
display(matrix(as.numeric(cp_app[3,2:785]), byrow = T,ncol = 28))
#4
# Quelle est la prÃ©diction faite par le modÃ¨le pour cette mÃªme image ?
which.max(calcul_sorties(RL_chiffres,cp_app[3,2:785]))
#4
# Calculer le nombre de bonnes prÃ©dictions que fait ce modÃ¨le sur le jeu d'apprentissage
zz=(calcul_sorties(RL_chiffres,cp_app[,2:785]))
# A FAIRE
predict_cp_app=apply(zz,2,which.max)
# Donner la matrice de confusion associÃ©e au jeu d'apprentissage
# A FAIRE
Mat_val=table(predict_cp_app,cp_app$label)
Mat_val
Mat_val
# Donner la matrice de confusion associÃ©e au jeu d'apprentissage
# A FAIRE
Mat_val=table(predict_cp_app,cp_app$label)
#4
# Quelle est la prÃ©diction faite par le modÃ¨le pour cette mÃªme image ?
which.max(calcul_sorties(RL_chiffres,cp_app[3,2:785]))
#4
# Calculer le nombre de bonnes prÃ©dictions que fait ce modÃ¨le sur le jeu d'apprentissage
zz=(calcul_sorties(RL_chiffres,cp_app[,2:785]))
# A FAIRE
predict_cp_app=apply(zz,2,which.max)
# Donner la matrice de confusion associÃ©e au jeu d'apprentissage
# A FAIRE
Mat_val=table(predict_cp_app,cp_app$label)
Mat_val
Mat_v=table(predict_cp_val,cp_val$label)
Mat_v=table(predict_cp_val,cp_val$label)
# A FAIRE
predict_cp_app=apply(zz,2,which.max)
predict_cp_val=apply(zp,2,which.max)
# Calculer le nombre (et le proucentage) de bonnes prÃ©dictions sur l'ensemble de validation
# A FAIRE
zp=(calcul_sorties(RL_chiffres,cp_val[,2:785]))
Mat_v=table(predict_cp_val,cp_val$label)
# A FAIRE
predict_cp_app=apply(zz,2,which.max)
# Donner la matrice de confusion associÃ©e au jeu d'apprentissage
# A FAIRE
Mat_val=table(predict_cp_app,cp_app$label)
Mat_val
# Calculer le nombre (et le proucentage) de bonnes prÃ©dictions sur l'ensemble de validation
# A FAIRE
zp=(calcul_sorties(RL_chiffres,cp_val[,2:785]))
Mat_v=table(predict_cp_val,cp_val$label)
predict_cp_val=apply(zp,2,which.max)
Mat_v=table(predict_cp_val,cp_val$label)
Mat_v
predict_cp_val
Nbre_ok_val=sum( predict_cp_val==cp_val[,1])
Nbre_ok_val
# Donner la matrice de confusion associÃ©e au jeu de validation
# A FAIRE
Mat_val2=table(predict_cp_val,cp_val[,1])
Mat_val2
# Quels sont les chiffres qui sont le plus souvent confondus par ce modÃ¨le ?
# 7 et 9
# Affichez des instances de ces chiffres correctement classÃ©es. De mÃªme avec des instances incorrectement classÃ©es. (avec la commande display)
display(matrix(as.numeric(cp_app[4,2:785]), byrow = T,ncol = 28))
# Lecture du fichier PNG dans R
monimage = readPNG("test1.png")[,,1] # si probleme essayez monimage = readPNG("test1.png")
# Lecture du fichier PNG dans R
monimage = readPNG("test1.png")[,,1] # si probleme essayez monimage = readPNG("test1.png")
# Lecture du fichier PNG dans R
monimage = readPNG("test1.png")[,,1] # si probleme essayez monimage = readPNG("test1.png")
# Lecture du fichier PNG dans R
monimage = readPNG("test1.png")[,,1] # si probleme essayez monimage = readPNG("test1.png")
# Lecture du fichier PNG dans R
monimage = readPNG("test1.png")[,,1] # si probleme essayez monimage = readPNG("test1.png")
# Lecture du fichier PNG dans R
monimage = readPNG("test1.png")[,,1] # si probleme essayez monimage = readPNG("test1.png")
dim(monimage)
monimage = readPNG("test1.png")
install.packages("png")
# Lecture du fichier PNG dans R
monimage = readPNG("test1.png")[,,1] # si probleme essayez monimage = readPNG("test1.png")
# Lecture du fichier PNG dans R
monimage = readPNG("test1.png")[,,1] # si probleme essayez monimage = readPNG("test1.png")
monimage = readPNG("test1.png")
library(png)
install.packages("png")
install.packages("png")
monimage = readPNG("test1.png")
